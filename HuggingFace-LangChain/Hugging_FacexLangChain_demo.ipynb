{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oDGHh_d3ocr",
        "outputId": "73cd2bdd-ef27-4d40-a574-fd8201bd1571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.0.1-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting huggingface-hub>=0.23.0 (from langchain-huggingface)\n",
            "  Downloading huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting langchain-core<0.3,>=0.1.52 (from langchain-huggingface)\n",
            "  Downloading langchain_core-0.2.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from langchain-huggingface) (2.7.0)\n",
            "Collecting text-generation<0.8.0,>=0.7.0 (from langchain-huggingface)\n",
            "  Downloading text_generation-0.7.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from langchain-huggingface) (0.19.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from langchain-huggingface) (4.40.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2023.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.1)\n",
            "Requirement already satisfied: requests in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (0.1.48)\n",
            "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (1.10.12)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (8.2.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.2.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.11.4)\n",
            "Requirement already satisfied: Pillow in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.2.0)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.8 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from text-generation<0.8.0,>=0.7.0->langchain-huggingface) (3.9.3)\n",
            "Collecting pydantic<3,>=1 (from langchain-core<0.3,>=0.1.52->langchain-huggingface)\n",
            "  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
            "     ---------------------------------------- 0.0/107.3 kB ? eta -:--:--\n",
            "     ---------- -------------------------- 30.7/107.3 kB 640.0 kB/s eta 0:00:01\n",
            "     ------------------------------------ - 102.4/107.3 kB 1.2 MB/s eta 0:00:01\n",
            "     -------------------------------------- 107.3/107.3 kB 1.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2023.10.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.8->text-generation<0.8.0,>=0.7.0->langchain-huggingface) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.8->text-generation<0.8.0,>=0.7.0->langchain-huggingface) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.8->text-generation<0.8.0,>=0.7.0->langchain-huggingface) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.8->text-generation<0.8.0,>=0.7.0->langchain-huggingface) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.8->text-generation<0.8.0,>=0.7.0->langchain-huggingface) (1.9.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.52->langchain-huggingface) (3.10.1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-huggingface)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.18.2 (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-huggingface)\n",
            "  Downloading pydantic_core-2.18.2-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.2.2)\n",
            "Requirement already satisfied: sympy in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.3)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2021.4.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface) (0.4.6)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (2.2.0)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2021.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Downloading langchain_huggingface-0.0.1-py3-none-any.whl (17 kB)\n",
            "Downloading huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n",
            "   ---------------------------------------- 0.0/401.3 kB ? eta -:--:--\n",
            "   --------------- ------------------------ 153.6/401.3 kB 4.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 401.3/401.3 kB 5.0 MB/s eta 0:00:00\n",
            "Downloading langchain_core-0.2.1-py3-none-any.whl (308 kB)\n",
            "   ---------------------------------------- 0.0/308.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 308.5/308.5 kB 9.6 MB/s eta 0:00:00\n",
            "Downloading text_generation-0.7.0-py3-none-any.whl (12 kB)\n",
            "Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
            "   ---------------------------------------- 0.0/409.3 kB ? eta -:--:--\n",
            "   --------------------------------------  399.4/409.3 kB 24.3 MB/s eta 0:00:01\n",
            "   --------------------------------------- 409.3/409.3 kB 12.5 MB/s eta 0:00:00\n",
            "Downloading pydantic_core-2.18.2-cp311-none-win_amd64.whl (1.9 MB)\n",
            "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
            "   ----------- ---------------------------- 0.5/1.9 MB 11.4 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 1.0/1.9 MB 10.9 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 1.5/1.9 MB 12.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  1.9/1.9 MB 11.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.9/1.9 MB 10.2 MB/s eta 0:00:00\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: pydantic-core, annotated-types, pydantic, huggingface-hub, text-generation, langchain-core, langchain-huggingface\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.12\n",
            "    Uninstalling pydantic-1.10.12:\n",
            "      Successfully uninstalled pydantic-1.10.12\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.22.2\n",
            "    Uninstalling huggingface-hub-0.22.2:\n",
            "      Successfully uninstalled huggingface-hub-0.22.2\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.1.50\n",
            "    Uninstalling langchain-core-0.1.50:\n",
            "      Successfully uninstalled langchain-core-0.1.50\n",
            "Successfully installed annotated-types-0.7.0 huggingface-hub-0.23.1 langchain-core-0.2.1 langchain-huggingface-0.0.1 pydantic-2.7.1 pydantic-core-2.18.2 text-generation-0.7.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "anaconda-cloud-auth 0.1.4 requires pydantic<2.0, but you have pydantic 2.7.1 which is incompatible.\n",
            "langchain 0.1.16 requires langchain-core<0.2.0,>=0.1.42, but you have langchain-core 0.2.1 which is incompatible.\n",
            "langchain-community 0.0.33 requires langchain-core<0.2.0,>=0.1.43, but you have langchain-core 0.2.1 which is incompatible.\n",
            "langchain-groq 0.1.3 requires langchain-core<0.2.0,>=0.1.45, but you have langchain-core 0.2.1 which is incompatible.\n",
            "langchain-objectbox 0.1.0a3 requires langchain-core<0.2.0,>=0.1.45, but you have langchain-core 0.2.1 which is incompatible.\n",
            "langchain-openai 0.1.3 requires langchain-core<0.2.0,>=0.1.42, but you have langchain-core 0.2.1 which is incompatible.\n",
            "langchain-text-splitters 0.0.1 requires langchain-core<0.2.0,>=0.1.28, but you have langchain-core 0.2.1 which is incompatible.\n",
            "langserve 0.1.0 requires langchain-core<0.2.0,>=0.1.0, but you have langchain-core 0.2.1 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
            "Requirement already satisfied: requests in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rishav bhattacharjee\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-huggingface\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## HuggingFacePipeline\n",
        "\n",
        "Among transformers, the Pipeline is the most versatile tool in the Hugging Face toolbox. LangChain being designed primarily to address RAG and Agent use cases, the scope of the pipeline here is reduced to the following text-centric tasks: “text-generation\", “text2text-generation\", “summarization”, “translation”.\n",
        "\n",
        "Models can be loaded directly with the from_model_id method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "dbb269b3fc2749db8207cd6bb4268143",
            "6c5b86249f1a4e51af4b6e4b129ab8b7",
            "1bd0c09239264781bea5fdd246ce4fee",
            "08f165733fb045498a361033c8319331",
            "dde76c50288d40f6b4cf9b18cb0585bd",
            "aba5cf5bae2f4b4799e149dd73e1c191",
            "891828a0f6df454c915a01d19f349ab6",
            "33ead0aae2a943bba37eb9b619552625",
            "15d6dd63c075496fb8e90cb7be282f84",
            "24f4620004574f16b68a80cb3723714f",
            "08ca36a20b284e4997c746cfb4e4d8fa"
          ]
        },
        "id": "MLOu5lla37-M",
        "outputId": "c0fd68a3-3f18-489e-e632-0a3404c465c1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e7808ef1f194f109f7c8484ee1fbe16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\RISHAV BHATTACHARJEE\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\RISHAV BHATTACHARJEE\\.cache\\huggingface\\hub\\models--google--gemma-2b-it. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0593b7191084c5c9da146c7cbfab013",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "344a8c01d5524a4faf9972a2e3e45f53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ae9a04b933b48269ac303f1d5b813a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d991ad335ea4f87b342be7dbfa9bf49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "daeb5195bcfc4fb2a34a6aa8b90a2ea4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ce430c1efd0439691b32cb73463d9ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1481142b6d04e94bddc0aad80662d52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "829e54454ccd434486458796e66539f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
            "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52f4eec9a17648ab88e73aee44a89ef8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9573078b0d747678cc315c1bafdb9ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "                            model_id=\"google/gemma-2b-it\",\n",
        "                           task = \"text-generation\",\n",
        "                           pipeline_kwargs = {\"temperature\":0.1, \"max_new_tokens\":100,\"top_k\":50 }\n",
        "                           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7xPrpROz6rJ8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\RISHAV BHATTACHARJEE\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'What is langchain? '"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"What is langchain? \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using HuggingFaceEndPoint\n",
        "\n",
        "There are also two ways to use this class. You can specify the model with the repo_id parameter. Those endpoints use the serverless API, which is particularly beneficial to people using pro accounts or enterprise hub. Still, regular users can already have access to a fair amount of request by connecting with their HF token in the environment where they are executing the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to C:\\Users\\RISHAV BHATTACHARJEE\\.cache\\huggingface\\token\n",
            "Login successful\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\" a popular open-source library that provides a simple and efficient way to use pre-trained models for natural language processing (NLP) tasks. In this article, we will explore how to use Hugging Face's Transformers library to fine-tune a pre-trained language model for sentiment analysis.\\n\\n**Prerequisites**\\n\\nBefore we begin, make sure you have the following:\\n\\n* Python 3.8 or higher installed\\n* Hugging Face's Transformers library installed (you can install it using `pip install transformers`)\\n\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id = \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    task = \"text-generation\",\n",
        "    max_new_tokens = 100,\n",
        "    do_sample=False,\n",
        ")\n",
        "\n",
        "llm.invoke(\"Hugging face is\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08ca36a20b284e4997c746cfb4e4d8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08f165733fb045498a361033c8319331": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24f4620004574f16b68a80cb3723714f",
            "placeholder": "​",
            "style": "IPY_MODEL_08ca36a20b284e4997c746cfb4e4d8fa",
            "value": " 1/2 [00:20&lt;00:20, 20.53s/it]"
          }
        },
        "15d6dd63c075496fb8e90cb7be282f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bd0c09239264781bea5fdd246ce4fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33ead0aae2a943bba37eb9b619552625",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15d6dd63c075496fb8e90cb7be282f84",
            "value": 1
          }
        },
        "24f4620004574f16b68a80cb3723714f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ead0aae2a943bba37eb9b619552625": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c5b86249f1a4e51af4b6e4b129ab8b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aba5cf5bae2f4b4799e149dd73e1c191",
            "placeholder": "​",
            "style": "IPY_MODEL_891828a0f6df454c915a01d19f349ab6",
            "value": "Loading checkpoint shards:  50%"
          }
        },
        "891828a0f6df454c915a01d19f349ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aba5cf5bae2f4b4799e149dd73e1c191": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbb269b3fc2749db8207cd6bb4268143": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c5b86249f1a4e51af4b6e4b129ab8b7",
              "IPY_MODEL_1bd0c09239264781bea5fdd246ce4fee",
              "IPY_MODEL_08f165733fb045498a361033c8319331"
            ],
            "layout": "IPY_MODEL_dde76c50288d40f6b4cf9b18cb0585bd"
          }
        },
        "dde76c50288d40f6b4cf9b18cb0585bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
