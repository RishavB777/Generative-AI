{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='An Empirical Study with Pre Trained and Attention Model\\non Food Disease Classification\\nA Project submitted in partial fulfillment of requirements\\nFor the award of the degree of\\nMaster of Computer Application\\nby\\nSohom Roy Choudhury\\nRegn. No.- 221040510049 Exam Roll No. - 12022010010038\\nRishav Bhattacharjee\\nRegn. No.- 221040510036 Exam Roll No. - 12022010010008\\nAyan Batabyal\\nRegn. No.- 221040510011 Exam Roll No. - 12022010010003\\nunder the supervision of\\nProf. Supratim Ghosh\\nAssistant Professor\\n&\\nProf. Dr. Priti Deb\\nAssistant Professor\\nDepartment of Computer Application\\nInstitute of Engineering & Management\\nKolkata, West Bengal, India\\n2022-2024', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 0}),\n",
       " Document(page_content='Declaration Certificate\\nThis is to certify that the work presented in the thesis entitled “An Empirical Study with\\nPre-Trained and Attention Model on Food Disease Classification” in partial fulfilment of\\nthe requirement for the award of degree of Master of Computer Application of Institute of\\nEngineering & Management is an authentic carried out under my supervision and guidance.\\nTo the best of my knowledge the content of this thesis dose not form a basis for the award of\\nany previous degree to anyone else.\\nProf. Supratim Ghosh ,\\nAssistant Professor,\\nDepartment of Computer Application,\\nInstitute of Engineering & Managemnet.\\n(Supervisor)\\nProf. Dr. Priti Deb ,\\nAssistant Professor,\\nDepartment of Computer Application,\\nInstitute of Engineering & Managemnet.\\n(Supervisor)\\nHead of the Department,\\nMaster of Computer Application and Sciences,\\nInstitute of Engineering & Management.\\nI', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 1}),\n",
       " Document(page_content='Certificate of Approval\\nThe for going thesis entitled “An Empirical Study with Pre-Trained and Attention\\nModel on Food Disease Classification” is hereby approved as a creditable study of research\\ntopic and has been presented in satisfactory manner to warrant its acceptance as prerequisite to\\nthe degree for which it has been submitted.\\nIt is understood by this approval, the undersigned do not necessarily endorse any conclusion or\\nopinion expressed there in, but approve the thesis for the purpose for which it is submitted.\\nExaminers:\\n(Signature of The Examiner) (Signature of The Supervisor)\\n(Signature of The Supervisor)\\nII', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 2}),\n",
       " Document(page_content='ACKNOWLEDGEMENT\\nWe would like to express our special thanks to our supervisor, Prof. Supratim Ghosh and Prof.\\nDr. Priti Deb who helped us a lot in this project, their valuable suggestions helped us to solve tough\\nchallenges and without their help this project could not have been completed in time. A special\\nthanks to them who gave us the golden oppurtunity to do this wonderful project on the topic “An\\nEmpirical Study with Pre Trained and Attention Model on Food Disease Classification”, which\\nhelped us to gain a significant knowledge in the aforesaid subjects. We would also like to express\\nour warm regards as a note of thanks to Prof. Dr. Pawan Kumar Singh of Jadavpur University(IT\\nDepartment) and Prof. Debam Saha of Calcutta Institute of Engineering and Management( CSE\\nDepartment) for their wonderful support for their help on this topic. Secondly, we would like to\\nthank our friends who helped us a lot in finalising this project within the given time frame.\\nSohom Roy Choudhury\\nRoll No. - 12022010010038\\nDepartment of Computer Application,\\nInstitute of Engineering & Management.\\nRishav Bhattacharjee\\nRoll No. - 12022010010008\\nDepartment of Computer Application,\\nInstitute of Engineering & Management.\\nAyan Batabyal\\nRoll No. - 12022010010003\\nDepartment of Computer Application,\\nInstitute of Engineering & Management.\\nIII', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 3}),\n",
       " Document(page_content='Contents\\nCertificate from Supervisor I\\nCertificate of Approval II\\nAcknowledgement III\\n1 Introduction 1\\n1.1 Research Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n1.2 Organization of Thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n2 Literature Survey 4\\n3 Methodology 7\\n3.1 Materials and methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3.1.1 VGG . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n3.1.2 ResNet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.1.3 DenseNet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\n3.1.4 MobileNet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n3.1.5 Squeeze-Excitation Attention Networks . . . . . . . . . . . . . . . . . . . . . 13\\n4 Experiments 15\\n4.1 Hardware Used . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\n4.2 Optimizer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n4.3 Loss Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n5 Dataset Details 17\\n5.1 PLD(Potato Leaf Disease) dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n5.2 Fruit Infection Disease dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\n5.3 Dataset Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n6 Result and Analysis 23\\n6.1 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n6.2 Classification metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n6.3 Confusion Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\n6.4 Experimental Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 4}),\n",
       " Document(page_content='6.5 Performance Comparison between Top-3 State of the Art for the Dataset PLD\\n(Potato Leaf Disease) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n6.6 Performance Comparison between Top-3 State of the Art with Attention Model for\\nthe Dataset PLD (Potato Leaf Disease) . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n6.7 Performance Comparison between Top-3 State of the Art for the Dataset FID (Fruit\\nInfection Disease) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n6.8 Performance Comparison between Top-3 State of the Art with Attention Model for\\nthe Dataset FID (Fruit Infection Disease) . . . . . . . . . . . . . . . . . . . . . . . . 28\\n6.9 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n7 Conclusion and Future Work 30\\n7.1 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\n7.2 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\nV', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 5}),\n",
       " Document(page_content='List of Figures\\n3.1 VGG Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.2 ResNet Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\n3.3 DenseNet Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n3.4 MobileNet Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n3.5 Squeeze - Excitation Attention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\n5.1 Sample Images from PLD(Potato Leaf Disease) dataset . . . . . . . . . . . . . . . . 18\\n5.2 Sample Images from Strawberry Anthracnos Fruit Rot . . . . . . . . . . . . . . . . . 19\\n5.3 Sample Images from Strawberry Gray Mold . . . . . . . . . . . . . . . . . . . . . . . 19\\n5.4 Sample Images from Tomato Leaf Mold . . . . . . . . . . . . . . . . . . . . . . . . . 19\\n5.5 Sample Images from Tomato Spider Miles . . . . . . . . . . . . . . . . . . . . . . . . 20\\n5.6 Sample Images from Beans Rust . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n5.7 Sample Images from Beans Angular Leaf Spot . . . . . . . . . . . . . . . . . . . . . . 20\\n5.8 Bar graph depicting PLD dataset distribution . . . . . . . . . . . . . . . . . . . . . . 21\\n5.9 Bar graph depicting FID dataset distribution . . . . . . . . . . . . . . . . . . . . . . 22\\n6.1 Confusion Matrix Achieved on PLD using Only Base model DenseNet121 . . . . . . 25\\n6.2 Confusion Matrix Achieved on PLD using Only Base model MobileNet . . . . . . . . 25\\n6.3 Confusion Matrix Achieved on PLD using Only Base model ResNet101V2 . . . . . . 25\\n6.4 Confusion Matrix Achieved on PLD using Base model DenseNet121 with SE Atten-\\ntion Block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n6.5 Confusion Matrix Achieved on PLD using Base model MobileNet with SE Attention\\nBlock . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n6.6 Confusion Matrix Achieved on PLD using Base model ResNet101V2 with SE Atten-\\ntion Block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n6.7 Confusion Matrix Achieved on FID using Only Base model MobileNet . . . . . . . . 27\\n6.8 Confusion Matrix Achieved on FID using Only Base model ResNet101V2 . . . . . . 27\\n6.9 Confusion Matrix Achieved on FID using Only Base model DenseNet121 . . . . . . . 27\\n6.10 Confusion Matrix Achieved on FID using Base model with SE Attention Block\\nResNet101V2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n6.11 Confusion Matrix Achieved on FID using Base model with SE Attention Block Mo-\\nbileNet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n6.12 Confusion Matrix Achieved on FID using Base model with SE Attention Block\\nDenseNet121 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 6}),\n",
       " Document(page_content='List of Tables\\n6.1 Top-3 State of the art for the Dataset PLD . . . . . . . . . . . . . . . . . . . . . . . 25\\n6.2 Top-3 State of the art for the Dataset PLD with Attention Model . . . . . . . . . . . 26\\n6.3 Top-3 State of the art for the Dataset FID . . . . . . . . . . . . . . . . . . . . . . . . 27\\n6.4 Top-3 State of the art for the Dataset FID with Attention Model . . . . . . . . . . . 28', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 7}),\n",
       " Document(page_content='Abstract\\nFood is an important sector for a country which gets affected by an\\ninnumerable diseases at an early stage. These diseases affect the\\nvarious crops which ultimately decreases the productivity of these\\nfood crops.This thesis investigates the classification of food diseases\\nemploying deep learning models. Various well-established architec-\\ntures such as DenseNet201, DenseNet121, ResNet50V2, ResNet101V2,\\nVGG16, VGG19, MobileNetV2, and MobileNet are trained on two dis-\\ntinct datasets: Potato Leaf Disease (PLD) and Food Infection Disease\\n(FID). Notably, among these models, MobileNet, ResNet101V2, and\\nDenseNet121 exhibit superior performance. Furthermore, the integra-\\ntion of an attention mechanism, specifically the squeeze and excitation\\n(SE) module, enhances classification accuracy significantly. This aug-\\nmentation serves as a pivotal motivation for the present study. By\\nincorporating attention layers, the thesis demonstrates a notable im-\\nprovement in accuracy levels, underscoring the potential of attention\\nmechanisms in deep learning-based disease classification tasks. Such\\nfindings not only advance the understanding of deep learning applica-\\ntions in disease diagnosis but also highlight the importance of attention\\nmechanisms in refining model performance.\\nKeyword: Deep Learning, Food Disease Classification, Squeeze and\\nExcitation, DenseNet201, DenseNet121, ResNet50V2, ResNet101V2,\\nVGG16, VGG19, MobileNetV2, MobileNet, Potato Leaf Disease (PLD)\\nand Food Infection Disease (FID).', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 8}),\n",
       " Document(page_content='Chapter 1\\nIntroduction\\nThe exploration of deep learning methodologies in revolutionizing disease classification within the\\nagricultural staples of potatoes and apples represents a critical endeavor in addressing the pervasive\\nthreats posed by crop diseases. These two staples, integral to global sustenance and economies, are\\nconstantly besieged by a myriad of diseases orchestrated by insidious invaders such as fungi, bacteria,\\nand viruses. The repercussions of these diseases reverberate far beyond individual farms, exerting\\nprofound impacts on the livelihoods of farmers and the broader global food security landscape.\\nThus, the timely and precise detection of diseases stands as a pivotal linchpin for implementing\\ntargeted interventions, minimizing yield losses, and safeguarding food supplies.\\nTraditionally, the laborious task of disease detection has relied on visual inspections conducted\\nby experts. However, this method is fraught with challenges—it is time-consuming, labor-intensive,\\nand inherently susceptible to human error. Recognizing the limitations inherent in traditional\\napproaches, this research heralds a paradigm shift by harnessing the capabilities of deep learning\\nto surmount these challenges. Eight distinct deep learning models, each endowed with unique\\nstrengths, are slated for rigorous evaluation. Among them are DenseNet201 and ResNet50V2,\\ncelebrated for their prowess in image classification, alongside MobileNetV2, tailored for efficiency\\non mobile devices. The primary objective is to assess their efficacy in accurately classifying a broad\\nspectrum of potato leaf and apple diseases. This comprehensive evaluation will be multifaceted,\\nscrutinizing classification accuracy, computational efficiency, and scalability. The overarching aim is\\nto pinpoint the front runner—the model capable of delivering superior disease classification accuracy\\nwithout exacting an exorbitant computational toll.\\nHowever, the research endeavor does not culminate with model evaluation. It delves deeper\\ninto the realm of transfer learning and fine-tuning strategies to explore their potential in further\\nenhancing model performance. Consider a deep learning model pre-trained on an extensive dataset\\nof generic plant images. Such a model has already assimilated a wealth of knowledge about visual\\nfeatures. Transfer learning empowers researchers to leverage this pre-existing knowledge and adapt\\nit to the specific challenge of potato and apple disease classification. Fine-tuning takes this adapta-\\ntion a step further, meticulously calibrating the model’s internal parameters to refine its ability to\\ndiscern healthy crops from those afflicted by disease. This exploration holds promise not only for\\naugmenting model performance but also for significantly curtailing the time required for training.\\nUltimately, the research endeavors to bridge the chasm between cutting-edge technological in-\\nnovations and the pragmatic exigencies of real-world agricultural settings. By rigorously evaluating\\n1', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 9}),\n",
       " Document(page_content='the performance of these deep learning models, the research aims to ascertain their viability as\\nreliable and efficient tools for farmers. Envision a future where farmers can seamlessly leverage a\\nsmartphone application equipped with a deep learning model to swiftly and accurately diagnose\\ndiseases in their crops. Such technology harbors the potential to transform crop health monitoring,\\nenabling early detection and intervention and thereby fostering a more resilient food supply chain\\nand sustainable agricultural practices.\\nMoreover, the implications of this research extend beyond disease classification alone. By de-\\nmocratizing access to advanced technological solutions, such as deep learning models, even to\\nresource-constrained farming communities, the research contributes to narrowing the digital di-\\nvide in agriculture. Furthermore, the integration of deep learning into agricultural practices opens\\navenues for data-driven decision-making, precision agriculture, and the optimization of resource al-\\nlocation. By harnessing the power of data analytics and artificial intelligence, farmers can optimize\\ninputs, minimize waste, and maximize yields, thereby fostering greater sustainability in agricultural\\nproduction.\\nIn essence, the transformative potential of deep learning in revolutionizing disease classification\\nwithin potatoes and apples signifies a watershed moment in agricultural innovation. By transcend-\\ning the limitations of traditional disease detection methods, deep learning empowers farmers with\\nthe tools needed to safeguard their crops, enhance productivity, and fortify global food security.\\nAs such, this research not only underscores the pivotal role of technology in addressing contempo-\\nrary agricultural challenges but also heralds a future where innovation serves as a cornerstone for\\nbuilding resilient and sustainable food systems.\\n1.1 Research Motivation\\nAgriculture is a cornerstone of South Asian economies, including India. This thesis focuses on a\\ncritical challenge: early and accurate detection of crop diseases like Potato Leaf Disease (PLD) and\\nothers causing Food Infection Diseases (FID). Early detection minimizes crop losses and wasted\\nhuman labor, a crucial resource in the region. This research proposes a solution using deep learning\\nto automate disease classification. By automating this process, farmers can save valuable time and\\neffort traditionally spent on manual inspection. Additionally, accurate classification ensures only\\nhealthy crops reach consumers. This translates to better food quality and contributes to improved\\npublic health and hygiene. In essence, this thesis aims to leverage technology for a two-fold benefit:\\nprotecting crops and enhancing public health throughout South Asia.\\n1.2 Organization of Thesis\\nThe thesis is distributed into seven chapters. Chapter 1 provides an introduction to the thesis. The\\nrest of the thesis is as follows:\\n•Chapter 2 provides a literature review of several classification-based approaches. In this\\nchapter, we have reviewed the publications that have been conducted on the topic of catego-\\nrization.\\n•Chapter 3 provides information about the methodology of our work. In this chapter, we\\nhave provided information about all the state-of-the-art image classification models we have\\nused for our work as well as the flow of our work.\\n2', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 10}),\n",
       " Document(page_content='•Chapter 4 provides all the experimentation details. This chapter consists of the hardware\\nspecifications, optimizer and loss functions we used for our work.\\n•Chapter 5 provides information about the dataset nomenclature. In this chapter, we have\\ndiscussed detailly on both the datasets we used.\\n•Chapter 6 provides all the results that we have obtained after several testing. This chapter\\nconsists of comparison of results that are obtained on the eight base models as well as further\\nenhancements. The comparison of results includes a training accuracy and validation accuracy\\ncurves, training loss and validation loss curves, confusion matrix, and classification report.\\n3', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 11}),\n",
       " Document(page_content='Chapter 2\\nLiterature Survey\\nIn recent years, the agricultural sector has been increasingly challenged by the detrimental impacts\\nof plant diseases on crop yield and quality. Among these afflictions, leaf diseases stand out as\\nsignificant contributors to agricultural losses worldwide. The ability to accurately and efficiently\\nidentify these diseases is paramount for implementing timely and targeted management strategies\\nto mitigate their effects. With the advent of advanced technologies, particularly in the domain of\\nmachine learning and computer vision, automated classification of food leaf diseases has emerged\\nas a promising approach to revolutionize disease diagnosis in agriculture. This section focuses on\\nthree aspects: (i) Some datasets related to our domain of work publicly available to develop and\\nvalidate them; (ii) different ways to measure the performance of an algorithm, and (iii) some recent\\nstate-of-the-art approaches available for image classification till date.\\nZoran et.at.[11] research introduces a new way to strengthen image recognition models by incor-\\nporating a human-like attention mechanism. They train a neural network with a special ”looking”\\nfeature inspired by how humans focus on key parts of an image. This ”looking” significantly\\nimproves the network’s ability to resist being fooled by altered images (adversarial attacks) and\\nachieves top performance on a large image dataset (ImageNet). Interestingly, the number of times\\nthe network ”looks” at an image can be adjusted to improve its defense, creating a competition\\nbetween attackers and the model. Finally, the tricks used to fool this new model are different\\n- they’re more obvious to humans and work by diverting the network’s attention from the main\\nobject.\\nTang et. al.[8] shows deep learning dominates flower classification, but models are complex and\\nrequire hefty training. This paper proposes a simpler approach: adding an attention mechanism to\\na CNN. This improves accuracy without burdening training, achieving a 2.81% boost on a 7-flower\\ndataset compared to standard attention.\\nNaik et. al.[2]chilli leaf diseases devastate crops. This study tackles this by using deep learn-\\ning (DL) to identify them. Researchers captured images of five common diseases and compared\\n12 pre-trained DL models. VGG19 excelled without data manipulation (83.54% accuracy), while\\nDarkNet53 shined with manipulation (98.82%). Pushing further, they built SECNN, a new model\\nachieving even better results (98.63% without manipulation, 99.12% with). Finally, SECNN success-\\nfully classified a wider range of plant leaf diseases (43 classes) with an impressive 99.28% accuracy.\\nLi Wang et. al.[9] classifies objects in hyperspectral images relies on both spectral and spatial\\ndata, but noise and inconsistencies can cause errors. To tackle this, a new approach using an\\n4', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 12}),\n",
       " Document(page_content='attention mechanism (SSSE) is proposed. SSSE assigns importance to different parts of the image\\ndata, focusing on valuable information and reducing the impact of noise. This SSSE module is\\nthen embedded in a larger network (SSSERN) for classification. Compared to existing methods\\non standard datasets, SSSERN achieves better accuracy, demonstrating its potential for cleaner\\nclassifications.\\nQiu et. al.[5] shows fish studies rely on data collection, which is expensive and labor-intensive.\\nTraditionally, scientists label fish images captured underwater. Deep learning can help, but classify-\\ning fish types (fine-grained classification) is tricky with low-quality, limited data. Existing methods\\nrequire a lot of high-quality data.This research tackles this by improving a technique called transfer\\nlearning. It creates high-quality images from the limited data and combines general and fish-specific\\ntraining. It also refines a specific building block within the deep learning model for better results.\\nTheir method surpasses traditional approaches on small fish image datasets, paving the way for\\nusing deep learning with limited data in fish research.\\nGuha Roy et. al.[6] show top image segmentation models, called F-CNNs, are constantly evolv-\\ning. While most progress targets how information travels through the network, this study looks at\\nenhancing the data itself. Inspired by a method named squeeze-and-excitation (SE), the authors\\nintroduce three variations specifically designed for image segmentation. These SE modules pin-\\npoint valuable features in images while downplaying unimportant ones. The authors successfully\\nincorporated these SE modules into existing F-CNNs, achieving consistent performance improve-\\nment across all models with minimal added complexity. To showcase effectiveness, they tested\\ntheir approach on challenging medical imaging tasks: brain segmentation in MRI scans and organ\\nsegmentation in CT scans.\\nZhong et.al.[10] show recent research shows wider networks improve image classification, but\\nsimply adding channels can be wasteful. This paper tackles this by proposing SE-WRNs-GVP,\\na new method for wider networks. It incorporates a special block (rSE-block) that retrieves lost\\ninformation during processing and focuses on informative channels. This approach achieves better\\nresults on standard datasets (CIFAR-10 and CIFAR-100) without increasing model complexity.\\nHu et. al.[1] show convolutional neural networks (CNNs) analyze images by combining spatial\\nand channel information. While effective, this approach has room for improvement. This paper\\nintroduces a new building block called a ”Squeeze-and-Excitation” (SE) block. SE blocks focus\\non how different channels in the data relate to each other, strengthening the overall network’s\\nunderstanding of the image. Notably, SE blocks significantly improve existing top CNNs without\\nmaking them much more complex. This approach formed the basis for the winning entry in the\\nILSVRC 2017 image recognition competition, achieving a significant accuracy jump.\\nPark et. al.[3] identifies insect species from images is a challenge, but deep learning offers\\npromise. Current methods struggle to differentiate between closely related species. This study\\nproposes a new model that tackles this by combining two techniques: squeeze-and-excitation mod-\\nules to highlight key features and attention modules to focus on crucial details. This allows for\\naccurate classification even with limited training data. Tested on an Australian insect dataset, the\\nnew model outperforms existing methods.\\nPatacchiola et.al.[4] research investigates personalizing AI systems for image classification tasks\\nwhen limited data is available. Current methods struggle to balance accuracy and computational\\nefficiency in this scenario. The authors propose a new building block called Contextual Squeeze-and-\\nExcitation (CaSE) to address this challenge. CaSE allows a pre-trained system to quickly adapt to\\na user’s specific data, significantly improving performance. The paper then introduces UpperCaSE,\\na method that combines CaSE blocks with fine-tuning for even better results. UpperCaSE achieves\\n5', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 13}),\n",
       " Document(page_content='state-of-the-art accuracy on standard datasets and real-world tasks while requiring substantially\\nless computing power compared to existing approaches.\\n6', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 14}),\n",
       " Document(page_content='Chapter 3\\nMethodology\\n3.1 Materials and methods\\nIn the pursuit of revolutionizing disease classification in plants, this research endeavor places the\\nspotlight on the formidable capabilities of Deep Learning (DL) models. The primary objective of\\nthis endeavor is to leverage DL models to accurately distinguish between healthy plants and those\\nafflicted by disease, harnessing insights gleaned from a comprehensive dataset comprising plant\\nimages. This choice is underpinned by DL’s demonstrated superiority in classification accuracy\\nwhen compared to conventional Machine Learning (ML) models.\\nDL models are favored for this task due to their innate capacity to discern intricate patterns and\\nfeatures within images, enabling them to effectively identify subtle indicators of disease presence.\\nUnlike traditional ML approaches, which often rely on handcrafted features and may struggle to\\ncapture complex relationships within data, DL models autonomously learn hierarchical representa-\\ntions of data, thereby enhancing their adaptability and robustness.\\nThe selection of DL models for this endeavor is strategic, guided by their proven efficacy in\\nimage classification tasks across diverse domains. Within the realm of DL architectures, several\\nprominent models are explored in this study, each renowned for its unique features and performance\\ncharacteristics.\\nVGG, characterized by its deep architecture and uniform convolution filter sizes, excels in captur-\\ning intricate details within images, making it particularly well-suited for tasks requiring fine-grained\\nclassification. ResNet, with its innovative residual learning framework, addresses the challenge of\\nvanishing gradients encountered in deeper networks, thereby facilitating the training of exception-\\nally deep models with improved performance. DenseNet, distinguished by its dense connectivity\\npatterns, promotes feature reuse and facilitates information flow across network layers, thereby en-\\nhancing model efficiency and interpretability. Meanwhile, MobileNet, optimized for deployment on\\nresource-constrained devices, strikes a balance between computational efficiency and classification\\naccuracy, making it an attractive option for real-world applications where computational resources\\nmay be limited.\\nEach of these DL architectures brings its own set of advantages to the task of disease classification\\nin plants. By systematically exploring and evaluating these models, researchers can gain insights\\ninto their relative strengths and weaknesses, thereby informing the selection of the most suitable\\nmodel for the specific requirements of the task at hand.\\n7', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 15}),\n",
       " Document(page_content='Furthermore, beyond the selection of DL models, this research endeavor encompasses a rigor-\\nous process of model training, validation, and optimization. Leveraging techniques such as data\\naugmentation, regularization, and hyper-parameter tuning, researchers endeavor to enhance the\\ngeneralization capabilities and robustness of the selected DL models, ensuring their efficacy in\\nreal-world deployment scenarios.\\nIn essence, by harnessing the power of DL models, this research endeavor aims to advance\\nthe frontier of plant disease classification, paving the way for more accurate, efficient, and scalable\\nsolutions for safeguarding global crop health and food security. Through a systematic exploration of\\nprominent DL architectures and rigorous model optimization, researchers endeavor to unlock new\\ninsights and capabilities in the realm of agricultural technology, ultimately empowering farmers\\nand stakeholders with the tools needed to combat plant diseases and foster sustainable agricultural\\npractices.\\n3.1.1 VGG\\nThe Visual Geometry Group (VGG)[7] models, comprising architectures like VGG16 and VGG19,\\nstand as pivotal milestones in the evolution of Convolutional Neural Network (CNN) architecture,\\nparticularly renowned for their simplicity and efficacy in image classification tasks. These models\\nhave left an indelible mark in the realm of computer vision, owing to their straightforward yet\\npowerful design principles. In Figure 3.1 we can see at the heart of VGG models lies a sequential\\narrangement of convolutional, pooling, and Rectified Linear Unit (ReLU) layers, forming a deep\\nnetwork capable of learning intricate features from input images. VGG16, one of the earliest it-\\nerations, boasts a CNN architecture composed of 16 layers, excluding the input layer. It unfolds\\nwith a series of convolutional layers followed by max-pooling layers, with ReLU activation func-\\ntions applied after each convolutional operation. This strategic design choice allows the network to\\nprogressively extract hierarchical features from input images, beginning with simple edges and tex-\\ntures and culminating in complex abstract representations. Notably, VGG16 employs small-sized\\nkernels, typically 3x3, in its convolutional layers, enabling the network to capture fine-grained fea-\\ntures essential for image classification tasks. The architecture concludes with fully connected layers\\nresponsible for producing classification predictions. Despite its considerable depth, VGG16 main-\\ntains a relatively straightforward and uniform architecture, making it accessible for understanding\\nand implementation. VGG19, an extension of VGG16, incorporates three additional convolutional\\nlayers, thereby escalating the layer count to 19. This augmentation aims to enhance the model’s\\ncapacity for feature extraction and representation. Similar to its predecessor, VGG19 adheres to\\nthe same architectural paradigm, encompassing convolutional layers, max-pooling layers, and ReLU\\nactivation functions. The additional layers in VGG19 confer increased model capacity, enabling the\\nnetwork to potentially glean more nuanced features from input images. However, this enhanced\\ncapability comes at the expense of heightened computational complexity. Due to its deeper architec-\\nture, VGG19 may exhibit improved performance compared to VGG16, especially when confronted\\nwith more complex datasets or tasks necessitating finer feature granularity. Both VGG16 and\\nVGG19 have etched their names as benchmark architectures in the domain of computer vision.\\nTheir versatility and robustness have rendered them indispensable in a plethora of applications,\\nranging from image classification and object detection to feature extraction. Researchers and prac-\\ntitioners alike have leveraged these architectures as foundational frameworks for tackling diverse\\ncomputer vision challenges, owing to their proven track record of efficacy and reliability. Moreover,\\nthe impact of VGG models extends beyond their immediate applications, transcending into the\\n8', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 16}),\n",
       " Document(page_content='realms of education and research. The simplicity and transparency of their architectures make\\nthem invaluable pedagogical tools for understanding the intricacies of deep learning and convolu-\\ntional neural networks. Additionally, their widespread adoption as benchmark models facilitates\\nfair and standardized evaluations across different research endeavors, fostering collaboration and\\nadvancing the collective understanding of computer vision principles. In essence, the VGG models,\\nepitomized by VGG16 and VGG19, stand as exemplars of effective CNN design, embodying the\\nprinciples of simplicity, efficacy, and versatility. Their enduring legacy continues to shape the land-\\nscape of computer vision, serving as pillars of innovation and progress in the quest for intelligent\\nvisual perception.\\nFigure 3.1: VGG Architecture\\n3.1.2 ResNet\\nThe evolution of deep neural network architectures has been punctuated by remarkable milestones,\\neach addressing specific challenges encountered in training and optimizing these complex models.\\nAmong these architectures, the Visual Geometry Group (VGG) models made significant strides\\nin advancing the field of image classification, owing to their simplicity and effectiveness. How-\\never, as researchers delved deeper into the development of increasingly complex networks, they\\nencountered challenges such as vanishing or exploding gradients, particularly as the depth of the\\nnetwork increased. These issues posed significant obstacles to training deep neural networks, im-\\npeding convergence and even leading to degradation in performance. To circumvent these chal-\\nlenges and enable the training of very deep networks, as seen in Figure 3.2 the ResNet (Residual\\nNetwork) architecture introduced a groundbreaking innovation: skip connections, also known as\\nresidual connections. These connections allowed the network to bypass certain layers, effectively\\ncreating shortcuts for the flow of information. By doing so, ResNet addressed the vanishing gra-\\ndient problem, facilitating the training of exceptionally deep neural networks. ResNet-50v2 and\\nResNet-101v2 represent variants of the original ResNet architecture, offering deeper networks with\\nsubstantial improvements in performance and representational capacity. ResNet-50v2, in particu-\\nlar, builds upon the successful ResNet architecture, introducing a 50-layer variant that retains the\\ncore principles of ResNet, including the use of residual connections. Despite the increased depth,\\nResNet-50v2 maintains computational efficiency and ease of training, thanks to the effectiveness\\nof residual connections in addressing gradient-related challenges. By striking a balance between\\ndepth and computational complexity, ResNet-50v2 emerges as a practical choice for a wide range\\nof image recognition tasks. ResNet-101v2, on the other hand, represents a further extension of the\\nResNet architecture, boasting 101 layers. With double the depth of ResNet-50v2, ResNet-101v2\\noffers even richer representations and potentially higher accuracy in image understanding tasks.\\nThe increased depth allows the network to learn more complex features and capture finer details\\nin images, which can be particularly advantageous in challenging datasets or domains. Despite the\\nadditional layers, ResNet-101v2 maintains the efficiency and effectiveness of residual connections,\\nensuring stable training and superior performance. The introduction of skip connections in ResNet\\n9', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 17}),\n",
       " Document(page_content='models like ResNet-50v2 and ResNet-101v2 marked a significant departure from earlier architec-\\ntures like VGG, enabling the training of deeper networks without encountering issues like vanishing\\ngradients. By allowing information to flow more freely through the network, skip connections facil-\\nitated the propagation of gradients during backpropagation, thereby accelerating convergence and\\nimproving the overall stability of training. Moreover, the efficacy of ResNet architectures in ad-\\ndressing gradient-related challenges has had profound implications for the field of computer vision.\\nThese advancements have contributed significantly to the state-of-the-art performance in various\\ntasks, including image classification, object detection, and semantic segmentation. By enabling\\nthe development of deeper and more expressive models, ResNet architectures have unlocked new\\nfrontiers in visual recognition, pushing the boundaries of what is achievable in terms of accuracy\\nand efficiency. Furthermore, the success of ResNet models has inspired further innovations in neural\\nnetwork architecture design, with researchers continually exploring new techniques for improving\\nthe performance and efficiency of deep learning models. From inception, ResNet has served as a\\ncatalyst for innovation, sparking a wave of research aimed at addressing the challenges inherent\\nin training deep neural networks. In conclusion, the introduction of skip connections in ResNet\\narchitectures like ResNet-50v2 and ResNet-101v2 represented a paradigm shift in the field of deep\\nlearning. By mitigating issues such as vanishing gradients, these architectures enabled the train-\\ning of exceptionally deep neural networks, pushing the boundaries of what is achievable in terms\\nof accuracy and performance. Moving forward, the legacy of ResNet will continue to inspire fur-\\nther advancements in neural network architecture design, driving progress in computer vision and\\nbeyond.\\nFigure 3.2: ResNet Architecture\\n3.1.3 DenseNet\\nAs seen in Figure 3.3 the DenseNet (Densely Connected Convolutional Network) architecture rep-\\nresents a significant advancement in the realm of deep learning, particularly renowned for its dense\\nconnectivity pattern. This group of Deep Learning (DL) models has garnered attention for its\\nunique design principles, which foster extensive information exchange between layers, facilitating\\nefficient feature reuse and mitigating challenges such as vanishing gradients. Among the DenseNet\\nvariants, DenseNet-201 and DenseNet-121 stand out as formidable tools for disease identification\\ntasks, offering increased depth and representational capacity while maintaining computational ef-\\nficiency. At the core of DenseNet architecture lies the concept of dense connectivity, where each\\nlayer within a block is connected to every other layer in a feed-forward manner. Unlike traditional\\n10', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 18}),\n",
       " Document(page_content='convolutional neural networks (CNNs) where information flows sequentially from one layer to the\\nnext, DenseNet forms dense connections between layers within the same block. This architecture\\npromotes an extensive exchange of information, ensuring that features learned by early layers are\\ndirectly utilized by subsequent layers. Consequently, DenseNet models exhibit enhanced represen-\\ntational capacity and are adept at capturing intricate patterns in input data. In DenseNet models,\\ndensely connected blocks serve as the building blocks of the network. Within each block, each layer\\nreceives direct input from all preceding layers, forming a dense connectivity pattern. This dense con-\\nnectivity ensures that information from earlier layers is preserved and propagated throughout the\\nnetwork, facilitating efficient feature reuse. By providing multiple paths for gradient flow, DenseNet\\nmitigates the risk of gradients becoming too small or vanishing as they propagate through the net-\\nwork. This property is particularly beneficial in deep architectures where maintaining gradient flow\\nis essential for effective training. DenseNet-201 represents a variant of the DenseNet architecture\\nwith 201 layers, offering increased depth and representational capacity. The additional layers in\\nDenseNet-201 enable the extraction of more intricate and abstract features from input images,\\nenhancing the model’s ability to discern subtle patterns indicative of plant diseases. The dense\\nconnectivity within DenseNet-201 ensures that features learned at different scales and abstraction\\nlevels are effectively integrated, contributing to improved disease identification accuracy. Despite\\nits increased depth, DenseNet-201 maintains computational efficiency, making it a practical choice\\nfor tasks where performance and accuracy are paramount. On the other hand, DenseNet-121 is\\nanother variant of the DenseNet architecture, featuring 121 layers. While less deep than DenseNet-\\n201, DenseNet-121 still benefits from dense connectivity and feature reuse mechanisms, making\\nit a powerful tool for plant disease identification tasks. DenseNet-121 strikes a balance between\\nmodel complexity and computational efficiency, making it suitable for scenarios where resource\\nconstraints are a concern without compromising performance significantly. The dense connectivity\\nand feature reuse mechanisms inherent in DenseNet-121 enable the model to effectively capture\\nand utilize intricate patterns in plant images, leading to accurate and reliable disease identification.\\nBy training DenseNet-201 and DenseNet-121 on plant images for disease identification, researchers\\naim to leverage the advantages of dense connectivity and feature reuse mechanisms inherent in\\nthese architectures. This approach enables the models to effectively capture and utilize intricate\\npatterns in plant images, leading to accurate and reliable identification of diseases. Additionally,\\nthe robustness and efficiency of DenseNet variants make them well-suited for real-world applica-\\ntions in agriculture, where timely and accurate disease identification is critical for ensuring crop\\nhealth and maximizing yields. In essence, DenseNet architectures represent a paradigm shift in\\ndeep learning, offering innovative solutions to challenges encountered in training deep neural net-\\nworks. By harnessing the power of dense connectivity and feature reuse mechanisms, DenseNet-201\\nand DenseNet-121 emerge as potent tools for disease identification tasks in agriculture, facilitating\\nthe development of robust and efficient solutions for plant health monitoring and management. As\\nresearch in this field continues to advance, DenseNet architectures are poised to play a pivotal role\\nin revolutionizing agricultural practices and ensuring global food security.\\n11', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 19}),\n",
       " Document(page_content='Figure 3.3: DenseNet Architecture\\n3.1.4 MobileNet\\nAs seen in the Figure 3.4 MobileNet model stands as a pivotal innovation in the landscape of\\nconvolutional neural network (CNN) architectures, specifically tailored for efficient and fast in-\\nference on mobile and embedded devices. In contrast to traditional CNN models, which often\\nimpose significant computational and memory burdens, MobileNet prioritizes a delicate balance\\nbetween model size, speed, and accuracy. This equilibrium is achieved through a series of key tech-\\nniques and architectural innovations that render MobileNet particularly suitable for deployment on\\nresource-constrained platforms. Central to the efficiency of MobileNet is its utilization of depth-wise\\nseparable convolutions, a technique that disentangles spatial and cross-channel information process-\\ning. Depth-wise separable convolutions comprise two distinct operations: depthwise convolutions\\nand pointwise convolutions. In the first step, depthwise convolutions are applied independently\\nto each input channel, thereby reducing the computational cost and memory footprint associated\\nwith traditional convolutions. Subsequently, pointwise convolutions are employed to combine the\\noutputs of depthwise convolutions across channels, facilitating cross-channel interactions without\\nintroducing excessive computational overhead. This separation of spatial and cross-channel in-\\nformation enables MobileNet to achieve a significant reduction in the number of parameters and\\ncomputations compared to conventional convolutions, thereby enhancing efficiency without sacri-\\nficing performance. Furthermore, MobileNet integrates lean versions of residual blocks, drawing\\ninspiration from the residual connections introduced in the pioneering ResNet architecture. These\\nresidual blocks play a crucial role in mitigating the risk of vanishing gradients, a common challenge\\nencountered in training deep neural networks. However, MobileNet’s implementation of residual\\nblocks is specifically optimized for efficiency, ensuring minimal computational overhead while still\\nproviding benefits in terms of training stability and convergence. By leveraging residual connec-\\ntions in a lightweight manner, MobileNet strikes an optimal balance between model complexity and\\ncomputational efficiency, making it well-suited for deployment on mobile and embedded devices.\\nMobileNetV2 represents a refinement and extension of the original MobileNet architecture, further\\noptimizing depth-wise separable convolutions and residual connections to enhance performance\\nand efficiency. One notable enhancement introduced in MobileNetV2 is the adoption of inverted\\n12', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 20}),\n",
       " Document(page_content='residual blocks with linear bottlenecks. These inverted residual blocks enable better utilization of\\ncomputational resources by allowing information to flow more efficiently through the network. Ad-\\nditionally, the linear bottlenecks serve to compress feature representations, effectively reducing the\\nmodel’s memory footprint while preserving expressive power. As a result, MobileNetV2 achieves\\nhigher accuracy and superior performance compared to its predecessor, all while maintaining a\\nsimilar level of efficiency and suitability for mobile and embedded deployment. Overall, MobileNet\\nrepresents a significant advancement in lightweight CNN architectures, offering efficient solutions\\nfor various computer vision tasks, particularly on mobile and embedded platforms. By leverag-\\ning depth-wise separable convolutions, lean residual blocks, and other architectural innovations,\\nMobileNet achieves a remarkable balance between model size, speed, and accuracy, making it an\\ninvaluable tool for deploying deep learning models in resource-constrained environments. With the\\ncontinuous evolution of the MobileNet family, including MobileNetV2 and MobileNet, the promise\\nof efficient and effective deep learning on mobile devices continues to be realized, opening up new\\nopportunities for ubiquitous AI applications in everyday life.\\nFigure 3.4: MobileNet Architecture\\n3.1.5 Squeeze-Excitation Attention Networks\\nAfter the top three models are chosen based on accuracy performance, as seen in Figure 3.5 Squeeze-\\nExcitation attention would be applied to those chosen models in order to boost their performance\\neven further. Squeeze-and-Excitation (SE) attention mechanism, introduced by Hu et al.[1] in\\n2018, enhances the representational power of convolutional neural networks (CNNs) by adaptively\\nrecalibrating feature maps based on channel-wise dependencies. The SE mechanism comprises two\\nkey operations: squeeze, where global average pooling compresses feature maps into channel-wise\\ndescriptors, and excitation, where learned weights are applied to these descriptors to emphasize\\ninformative channels and suppress irrelevant ones. By incorporating SE blocks into CNN architec-\\ntures, models can autonomously learn to focus on relevant features while discarding noise, leading\\nto improved performance across various tasks including image classification, object detection, and\\nsemantic segmentation. This attention mechanism enables networks to capture intricate spatial\\n13', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 21}),\n",
       " Document(page_content='and channel dependencies within feature maps, facilitating more effective feature representation\\nand consequently boosting overall accuracy and efficiency.\\nFigure 3.5: Squeeze - Excitation Attention\\n14', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 22}),\n",
       " Document(page_content='Chapter 4\\nExperiments\\nThe research conducted on the specified computer system utilizes various computational resources\\nand deep learning techniques to address a multi-class classification problem, specifically in the\\ncontext of plant disease identification.\\n4.1 Hardware Used\\nThe computer system described is well-equipped to handle a variety of computational tasks, par-\\nticularly those related to deep learning training and inference. At its core, it features an Intel Core\\ni5 9th Gen 9300H processor, which serves as the primary computational engine for executing tasks\\nsuch as model training, inference, and data preprocessing. The 9th Gen Intel Core i5 processor is\\nrenowned for its performance and efficiency, making it a suitable choice for demanding workloads\\nin machine learning and deep learning. Complementing the processor is 8GB of RAM (Random\\nAccess Memory), which plays a crucial role in managing data and computations during model\\ntraining and evaluation. The ample RAM capacity ensures that the system can efficiently handle\\nlarge datasets and complex neural network architectures without being bottlenecked by memory\\nconstraints. This is particularly important for deep learning tasks, where the manipulation of large\\nmatrices and tensors necessitates substantial memory resources. In terms of storage, the system\\nboasts a combination of a 1TB hard drive and a 256GB solid-state drive (SSD). This dual-storage\\nconfiguration offers the best of both worlds: the high capacity and affordability of a traditional hard\\ndrive, coupled with the speed and responsiveness of an SSD. The 1TB hard drive provides ample\\nspace for storing large datasets, model checkpoints, and other related files, while the 256GB SSD\\noffers fast read and write speeds, facilitating quick access to frequently used files and applications.\\nThis storage setup ensures that the system can efficiently manage the vast amounts of data typically\\ninvolved in deep learning tasks, while also providing fast access to critical files and resources. One\\nof the standout features of the system is its dedicated NVIDIA GeForce GTX 1650 graphics card\\nwith 4GB of memory. The GPU plays a crucial role in accelerating deep learning computations\\nusing parallel processing. Deep learning frameworks such as TensorFlow and PyTorch leverage the\\nparallel computing capabilities of GPUs to accelerate matrix multiplications and other compute-\\nintensive operations involved in training neural networks. By offloading these computations to the\\nGPU, the system can significantly reduce training times and improve overall performance. The\\nNVIDIA GeForce GTX 1650 is a capable GPU that strikes a balance between performance and\\n15', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 23}),\n",
       " Document(page_content='affordability, making it an excellent choice for deep learning enthusiasts and professionals alike. In\\nsummary, the computer system described offers a robust and well-rounded platform for deep learn-\\ning tasks. With its powerful Intel Core i5 processor, ample RAM, dual-storage configuration, and\\ndedicated NVIDIA GeForce GTX 1650 GPU, the system is well-equipped to handle a wide range\\nof machine learning and deep learning workloads. Whether training convolutional neural networks\\nfor image classification or recurrent neural networks for natural language processing, this system\\nprovides the computational power and resources necessary to tackle even the most demanding deep\\nlearning tasks with ease and efficiency.\\n4.2 Optimizer\\nThe Adam optimizer is selected for training the deep learning models due to its effectiveness in\\nnavigating the complexities of training neural networks. Adam stands out as a powerful optimizer\\nbecause of its adaptive learning rate mechanism, which adjusts learning rates dynamically for\\neach parameter during training. By combining the strengths of momentum and RMSProp, Adam\\nefficiently updates model parameters, accelerating convergence and improving training efficiency.\\n4.3 Loss Function\\nIn the context of multi-class classification, particularly in identifying various plant diseases, the\\nchoice of loss function is critical in guiding the learning process of the deep learning model. Cat-\\negorical Cross Entropy emerges as a suitable loss function for this research problem. Categorical\\nCross Entropy quantifies the dissimilarity between the predicted probability distribution and the\\ntrue probability distribution of the classes. This metric penalizes the model for incorrect classifi-\\ncations while rewarding it for accurate predictions, thereby steering the learning process towards\\nmore precise classifications. By employing Categorical Cross Entropy, the model can effectively\\nlearn from its mistakes and iteratively improve its classification performance over time. The loss\\nfunction provides valuable feedback to the model, enabling it to adjust its parameters in a manner\\nthat maximizes classification accuracy across different classes of images. This adaptive learning\\nprocess is crucial in tackling the nuances and complexities inherent in plant disease identification,\\nwhere subtle variations in symptoms and visual cues may distinguish between different diseases.\\nMoreover, the utilization of Categorical Cross Entropy facilitates the monitoring of classification\\nperformance for each class of images. This granular evaluation allows researchers to identify areas\\nof strength and weakness within the model’s predictive capabilities, thereby guiding further itera-\\ntions and refinements. Ultimately, the aim is to enhance the model’s ability to accurately identify\\nand classify various plant diseases, contributing to more effective disease management strategies\\nin agriculture. In summary, the research endeavors to leverage the computational resources of the\\nspecified computer system alongside advanced deep learning techniques such as the Adam optimizer\\nand Categorical Cross Entropy loss function. These methodological choices underscore a thought-\\nful consideration of efficiency, effectiveness, and accuracy in addressing real-world challenges at the\\nintersection of computer vision and agriculture. Through the judicious application of these tech-\\nniques, the research aims to advance the state-of-the-art in plant disease identification, ultimately\\ncontributing to improved crop health and agricultural productivity.\\n16', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 24}),\n",
       " Document(page_content='Chapter 5\\nDataset Details\\nThe research utilizes standard publicly available datasets to evaluate the performance of the Deep\\nLearning (DL) models in classifying plant images according to disease classes. These datasets\\nconsist of high-quality images capturing various plant diseases and are widely used for training and\\ntesting DL models in the field of plant pathology and agricultural informatics.\\n5.1 PLD(Potato Leaf Disease) dataset\\nIn this research, a standard dataset named the Potato Leaf Disease (PLD) dataset is introduced,\\ntailored specifically for the study of potato leaf diseases. The PLD dataset comprises a compre-\\nhensive collection of images capturing various manifestations of diseases affecting potato leaves, as\\nwell as images depicting healthy potato leaves for comparison. The dataset is structured into three\\nmain classes:\\n1.Early Blight: This class includes 1628 images of potato leaves exhibiting symptoms of\\nearly blight, a common fungal disease caused by the pathogen Alternaria solani. Early blight\\ntypically manifests as dark lesions with concentric rings on the leaves, leading to reduced\\nplant vigor and yield loss if left untreated.\\n2.Late Blight: The Late Blight class consists of 1414 images depicting potato leaves affected by\\nlate blight, a devastating disease caused by the oomycete pathogen Phytophthora infestans.\\nLate blight is characterized by water-soaked lesions that rapidly spread and can decimate\\nentire potato crops if not controlled effectively.\\n3.Healthy: This class comprises 1020 images of healthy potato leaves, devoid of any disease\\nsymptoms or abnormalities. Healthy leaves serve as a reference for comparison, enabling\\nresearchers to distinguish between diseased and non-diseased samples accurately.\\nThe dataset encompasses a diverse range of diseases commonly found in potatoes, providing a\\nvaluable resource for researchers and practitioners in the field of plant pathology and agriculture.\\nTo offer a visual representation of the dataset, sample images from each category are depicted in\\nFigure 5.1.\\n17', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 25}),\n",
       " Document(page_content='Figure 5.1: Sample Images from PLD(Potato Leaf Disease) dataset\\n5.2 Fruit Infection Disease dataset\\nIn this dataset, a total of 5494 images are included, each resized to a standard size of 416 x 416\\npixels to ensure uniformity across the dataset. The images are categorized into different classes,\\neach corresponding to specific diseases affecting different plant species. Below is a breakdown of\\nthe categories and the corresponding diseases.\\n•Strawberries\\n1. Angular Leaf Spot: 553 images\\n2. Anthracnose Fruit Rot: 214 images\\n3. Blossom Blight: 380 images\\n4. Gray Mold: 537 images\\n5. Leaf Spot: 650 images\\n18', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 26}),\n",
       " Document(page_content='6. Powdery Mildew (Fruit and Leaf): 375 images\\nFigure 5.2: Sample Images from Strawberry Anthracnos Fruit Rot\\nFigure 5.3: Sample Images from Strawberry Gray Mold\\n•Tomatoes\\n1. Disease (general): This category includes images depicting various diseases affecting\\ntomato plants, with 490 images available.\\n2. Leaf Mold: 490 images\\n3. Spider Mites: 484 images\\nFigure 5.4: Sample Images from Tomato Leaf Mold\\n19', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 27}),\n",
       " Document(page_content='Figure 5.5: Sample Images from Tomato Spider Miles\\n•Beans\\n1. Angular Leaf Spot: 407 images\\n2. Bean Rust: 469 images\\nFigure 5.6: Sample Images from Beans Rust\\nFigure 5.7: Sample Images from Beans Angular Leaf Spot\\nThe dataset encompasses a diverse range of diseases commonly found in strawberries, tomatoes, and\\nbeans, providing a valuable resource for researchers and practitioners in the field of plant pathology\\nand agriculture. To offer a visual representation of the dataset, sample images from each category\\nare depicted in Figure 5.2 to Figure 5.7.\\n20', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 28}),\n",
       " Document(page_content='5.3 Dataset Statistics\\nThis study presents the Potato Leaf Disease (PLD) dataset, an essential resource comprising metic-\\nulously curated images aimed at facilitating in-depth analysis of potato leaf diseases. Through its\\nmeticulously assembled collection, the dataset covers a diverse spectrum of disease manifestations\\nand healthy conditions, enabling comprehensive exploration of potato plant health. Structured\\ninto three primary categories, namely Early Blight, Late Blight, and Healthy, the dataset offers re-\\nsearchers a comprehensive framework for understanding disease progression and symptomatology.\\nEarly Blight, characterized by 1628 images, illuminates the fungal affliction instigated by Alternaria\\nsolani, while Late Blight, depicted in 1414 images, vividly portrays the destructive impact of Phy-\\ntophthora infestans. In contrast, the Healthy class, with 1020 images, provides crucial benchmarks\\nfor distinguishing between diseased and healthy states accurately. These images serve as invaluable\\ntools for researchers, facilitating precise disease identification and informing effective management\\nstrategies to safeguard potato crop yields and enhance agricultural productivity.\\nFigure 5.8: Bar graph depicting PLD dataset distribution\\nThe FID dataset comprises a total of 5494 images, each standardized to a size of 416 x 416 pixels\\nfor consistency. These images are organized into distinct categories, each representing specific\\ndiseases affecting various plant species. Among strawberries, the categories and corresponding\\ndiseases include Angular Leaf Spot (553 images), Anthracnose Fruit Rot (214 images), Blossom\\n21', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 29}),\n",
       " Document(page_content='Blight (380 images), Gray Mold (537 images), Leaf Spot (650 images), and Powdery Mildew (Fruit\\nand Leaf) (375 images). For tomatoes, categories encompass Disease (general) with 490 images\\ndepicting various ailments, Leaf Mold (490 images), and Spider Mites (484 images). Additionally,\\nfor beans, the dataset includes Angular Leaf Spot (407 images) and Bean Rust (469 images). This\\ncomprehensive breakdown provides researchers with a diverse range of visual data to facilitate\\nin-depth analysis and understanding of plant diseases across multiple species.\\nFigure 5.9: Bar graph depicting FID dataset distribution\\n22', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 30}),\n",
       " Document(page_content='Chapter 6\\nResult and Analysis\\n6.1 Evaluation\\nEvaluation metrics are employed to gauge the efficacy of the model, a crucial aspect in deep learning.\\nDiverse models are utilized to assess our dataset, and various metrics such as precision,recall and F1\\nscores are applied to scrutinize these models, since these are relying on classification methodologies.\\nThe eight models - DenseNet201, DenseNet121, ResNet50V2, ResNet101V2, VGG16, VGG19 ,\\nMobileNetV2 and MobileNetV3 - undergo training and testing using this dataset. We’ve attained\\nan accuracy of X1% for the DenseNet201 model, X2% for DenseNet121, X3% for ResNet50V2,\\nX4% for ResNet101V2, X5% for VGG16, X6% for VGG19, X7% for MobileNetV2 and X8% for\\nMobileNetV3 . In subsequent subsections, we delineate the metrics utilized for determining the\\nclassification accuracy of each model, presenting the achieved results accordingly.\\n6.2 Classification metrics\\n•Accuracy: Accuracy serves as a metric indicating the frequency with which the classifier\\ngenerates correct predictions. It is determined by the ratio of accurate forecasts to the total\\nnumber of predictions, offering a means to quantify the precision of the classifier.\\nAccuracyScore = (TP+TN)/(TP+TN+FP+FN) (6.1)\\n•Precision: The precision of a prediction is determined by assessing the ability to anticipate\\npositive observations. A low incidence of false positives indicates a higher level of accuracy.\\n1.True Positive (TP): This occurs when an outcome is positive and the model correctly\\npredicts it as positive.\\n2.True Negative (TN): This happens when an outcome is negative and the model\\ncorrectly predicts it as negative.\\n3.False Positive (FP): If the model incorrectly predicts negative outcomes as positive,\\nit results in false positives, also known as Type 1 Errors.\\n4.False Negative (FN): This occurs when the model incorrectly predicts positive out-\\ncomes as negative, resulting in false negatives, also known as Type 2 Errors.\\n23', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 31}),\n",
       " Document(page_content='Precision =TP/(TP+FP) (6.2)\\n•Recall: Recall assesses the classifier’s capability to identify positive observations within the\\ndataset. As the number of false negatives predicted by the model increases, the recall dimin-\\nishes.\\nRecall =TP/(TP+FN) (6.3)\\n1.Macro Averaged Recall: Macro Averaged Recall refers to the average of the recalls\\ncalculated for classes A, B, and C.\\nMacro Averaged Recall = 1−Accuracy (6.4)\\nIt informs us how frequently the model may be incorrect.\\n2.Micro Averaged Recall: The micro-average recall score is determined by dividing the\\naggregate number of true positives for every class by the total number of true positives\\nacross all classes.\\n•F1 Score: It’s a unified metric that incorporates both Precision and Recall, with the model’s\\nperformance enhancing as F1 scores increase. The F1-score ranges between 0 and 1, calcu-\\nlated as the weighted average of precision and recall. A high F1 score necessitates both high\\nprecision and recall from the classifier. This metric particularly rewards classifiers with bal-\\nanced precision and recall rates. The F1 score is a comprehensive measure that considers both\\naccuracy and recall, computed as the harmonic mean of precision and recall. Representing\\nthe F1 score using P for precision and R for recall, we have:\\nF1 = 2 PR/(P+R) (6.5)\\n1.Macro Averaged F1 score: The macro-averaged F1 score is determined by calculating\\nthe arithmetic mean of all individual class F1 scores.\\n2.Micro Averaged F1 score: Micro averaging computes the overall average F1 score by\\nsumming the True Positives (TP), False Negatives (FN), and False Positives (FP). To\\nobtain the micro F1 score, the TP, FP, and FN values across all classes are aggregated.\\n6.3 Confusion Matrix\\nThe assessment of classification models’ performance on a specific test dataset involves the use of\\na matrix known as the confusion matrix. This matrix can be computed only after obtaining the\\nactual values of the test data. While the structure of the matrix is straightforward to grasp, certain\\nterminologies associated with it might be perplexing. Occasionally labeled as an error matrix, it\\nillustrates the shortcomings in the model’s performance in matrix form.\\n6.4 Experimental Result\\nThis section scrutinizes the results produced by the eight deep learning models. The findings of\\nthe fundamental learners are visually depicted. Certain models demonstrate superior accuracy in\\nidentifying specific vehicles compared to others. Furthermore, a classification report detailing the\\naccuracy of the classifications and a confusion matrix are included.\\n24', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 32}),\n",
       " Document(page_content='6.5 Performance Comparison between Top-3 State of the\\nArt for the Dataset PLD (Potato Leaf Disease)\\nAfter training all eight of our base models on the PLD dataset, the top three best performing\\nmodels based on accuracy metric are: MobileNet, ResNet101V2, DenseNet121. DenseNet121 was\\nable to achieve top score with an accuracy of 96% after running it for 50 epochs using a batch size\\nof 32. On the other hand, ResNet101V2 was able to achieve an accuracy of 85% after running it\\nfor 55 epochs using a batch size of 32. Mobile Net was able to achieve an accuracy of 94% after\\nrunning it for 50 epochs using a batch size of 32.\\nTable 6.1: Top-3 State of the art for the Dataset PLD\\nModel Name Accuracy (%) Number of Epochs Batch Size\\nDenseNet121 96 50 32\\nMobileNet 94 50 32\\nResNet101V2 85 55 32\\nAs seen in the below Confusion matrix in Figure 6.4, DenseNet121 performed well on all the\\nclasses, with healthy class being misclassified as Late Blight 3% of the time. As seen in the below\\nConfusion matrix in Figure 6.5, MobileNet performed well on all the classes, with Early Blight class\\nbeing misclassified as healthy 3% of the time. As seen in the below Confusion matrix in Figure\\n6.6, ResNet101V2 performed well on all the classes, with healthy class being misclassified as Late\\nBlight 12% of the time.\\nFigure 6.1: Confusion\\nMatrix Achieved on\\nPLD using Only Base\\nmodel DenseNet121\\nFigure 6.2: Confusion\\nMatrix Achieved on\\nPLD using Only Base\\nmodel MobileNet\\nFigure 6.3: Confusion\\nMatrix Achieved on\\nPLD using Only Base\\nmodel ResNet101V2\\n25', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 33}),\n",
       " Document(page_content='6.6 Performance Comparison between Top-3 State of the\\nArt with Attention Model for the Dataset PLD (Potato\\nLeaf Disease)\\nAfter training all eight of our base models on the PLD dataset, the top three best performing models\\nbased on accuracy metric are: MobileNet, ResNet101V2, DenseNet121. After applying attention\\nmodel on them, DenseNet121 was able to achieve an accuracy of 97% after running it for 55 epochs\\nusing a batch size of 32. On the other hand, ResNet101V2 was able to achieve an accuracy of 88%\\nafter running it for 55 epochs using a batch size of 32. Mobile Net was able to achieve an accuracy\\nof 96% after running it for 50 epochs using a batch size of 32.\\nTable 6.2: Top-3 State of the art for the Dataset PLD with Attention Model\\nModel Name Accuracy (%) Number of Epochs Batch Size\\nDenseNet121 97 55 32\\nMobileNet 96 50 32\\nResNet101V2 88 55 32\\nAs seen in the below Confusion matrix in Figure 6.1, DenseNet121 performed well on all the\\nclasses, with healthy class being misclassified as Late Blight 6% of the time. As seen in the below\\nConfusion matrix in Figure 6.2, MobileNet performed well on all the classes, with Early Blight class\\nbeing misclassified as Late Blight 5% of the time. As seen in the below Confusion matrix in Figure\\n6.3, ResNet101V2 performed well on all the classes, with healthy class being misclassified as Late\\nBlight 14% of the time.\\nFigure 6.4: Confusion\\nMatrix Achieved on\\nPLD using Base model\\nDenseNet121 with SE\\nAttention Block\\nFigure 6.5: Confusion\\nMatrix Achieved on\\nPLD using Base model\\nMobileNet with SE\\nAttention Block\\nFigure 6.6: Confusion\\nMatrix Achieved on\\nPLD using Base model\\nResNet101V2 with SE\\nAttention Block\\n26', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 34}),\n",
       " Document(page_content='6.7 Performance Comparison between Top-3 State of the\\nArt for the Dataset FID (Fruit Infection Disease)\\nAfter training all eight of our base models on the FID dataset, the top three best performing models\\nbased on accuracy metric are: MobileNet, ResNet101V2, DenseNet121. DenseNet121 was able to\\nachieve an accuracy of 79% after running it for 45 epochs using a batch size of 32. On the other\\nhand, ResNet101V2 was able to achieve an accuracy of 82% after running it for 35 epochs using a\\nbatch size of 32. Mobile Net was able to achieve the highest accuracy among them with an accuracy\\nof 83% after running it for 45 epochs using a batch size of 32.\\nTable 6.3: Top-3 State of the art for the Dataset FID\\nModel Name Accuracy (%) Number of Epochs Batch Size\\nMobileNet 83 45 32\\nResNet101V2 82 35 32\\nDenseNet121 79 45 32\\nAs seen in the below Confusion matrix in Figure 6.7, MobileNet was able to identify Strawberry’s\\nLeaf Spot class correctly the best with 95% of the times the result being True Positive. MobileNet\\nperformed the worst against Strawberry’s Gray Mold class with 52% True Positivity. Beans’ Angular\\nLeaf spot class tricked MobileNet the most with 30% of the time it being classified as Beans’ Rust\\nclass. As seen in the below Confusion matrix in Figure 6.8, ResNet101V2 was able to identify\\nStrawberry’s Leaf Spot class correctly the best with 99% of the times the result being True Positive.\\nResNet101V2 performed the worst against Strawberry’s Gray Mold class with 50% True Positivity.\\nStrawberry’s Gray Mold class tricked ResNet101V2 the most with 32% of the time it being classified\\nas Strawberry’s Powdery Mildew Fruit class. As seen in the below Confusion matrix in Figure 6.9,\\nDenseNet121 was able to identify Tomato’s Spider Mites class correctly the best with 94% of the\\ntimes the result being True Positive. DenseNet121 performed the worst against Strawberry’s Gray\\nMold class with 53% True Positivity. Strawberry’s Anthracnose Fruit Rot class tricked DenseNet121\\nthe most with 27% of the time it being classified as Tomato’s Leaf Mold class.\\nFigure 6.7: Confusion\\nMatrix Achieved on FID\\nusing Only Base model\\nMobileNet\\nFigure 6.8: Confusion\\nMatrix Achieved on FID\\nusing Only Base model\\nResNet101V2\\nFigure 6.9: Confusion\\nMatrix Achieved on FID\\nusing Only Base model\\nDenseNet121\\n27', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 35}),\n",
       " Document(page_content='6.8 Performance Comparison between Top-3 State of the\\nArt with Attention Model for the Dataset FID (Fruit\\nInfection Disease)\\nAfter training all eight of our base models on the FID dataset, the top three best performing\\nmodels based on accuracy metric are: MobileNet, ResNet101V2, DenseNet121. After applying the\\nSqueeze-Excitation model, DenseNet121 was able to achieve an accuracy of 82% after running it\\nfor 45 epochs using a batch size of 32. On the other hand, ResNet101V2 was able to achieve an\\naccuracy of 86% after running it for 45 epochs using a batch size of 32. Mobile Net was able to\\nachieve an accuracy of 85% after running it for 35 epochs using a batch size of 32.\\nTable 6.4: Top-3 State of the art for the Dataset FID with Attention Model\\nModel Name Accuracy (%) Number of Epochs Batch Size\\nResNet101V2 86 45 32\\nMobileNet 85 35 32\\nDenseNet121 82 45 32\\nAs seen in the below Confusion matrix in Figure 6.7, MobileNet was able to identify Straw-\\nberry’s Leaf Spot class correctly the best with 99% of the times the result being True Positive.\\nMobileNet performed the worst against Strawberry’s Gray Mold class with 57% True Positivity.\\nStrawberry’s Anthracnose Fruit Rot, Blossom Blight, and Gray Mold classes got misclassified the\\nmost. As seen in the below Confusion matrix in Figure 6.8, ResNet101V2 was able to identify\\nStrawberry’s Leaf Spot class correctly the best with 99% of the times the result being True Pos-\\nitive. ResNet101V2 performed the worst against Strawberry’s Gray Mold class with 57% True\\nPositivity. Strawberry’s Anthracnose Fruit Rot, Blossom Blight, and Gray Mold classes got mis-\\nclassified the most. As seen in the below Confusion matrix in Figure 6.9, DenseNet121 was able to\\nidentify Tomato’s Leaf Mold class correctly the best with 100% of the times the result being True\\nPositive. DenseNet121 performed the worst against Strawberry’s Gray Mold class with 53% True\\nPositivity. Strawberry’s Anthracnose Fruit Rot, Blossom Blight, Gray Mold and PowderyMildew\\nFruit classes got misclassified the most.\\nFigure 6.10: Confusion\\nMatrix Achieved on FID\\nusing Base model with\\nSE Attention Block\\nResNet101V2\\nFigure 6.11: Confusion\\nMatrix Achieved on FID\\nusing Base model with\\nSE Attention Block\\nMobileNet\\nFigure 6.12: Confusion\\nMatrix Achieved on FID\\nusing Base model with\\nSE Attention Block\\nDenseNet121\\n28', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 36}),\n",
       " Document(page_content='6.9 Discussion\\nIn this work, while the overall performance has shown improvement compared to previous efforts in\\nthe field, there have been instances where certain images were misclassified due to various factors.\\nOne significant issue encountered during the preprocessing phase was related to the removal of\\nnoise from the images. Although noise removal techniques were applied using a threshold, which\\nproved effective for the majority of the images, it was not always optimal. The threshold chosen\\nfor noise removal during preprocessing may have been suitable for most images, but it failed to\\nadequately address noise in some cases. This lack of optimality in the threshold selection led\\nto the persistence of noise artifacts in certain images, despite attempts to mitigate them. As a\\nresult, a small sample of images ended up being misclassified due to the presence of residual noise.\\nThe presence of noise in images can significantly impact the performance of machine learning\\nmodels, particularly in tasks like image classification, where accurate feature extraction is crucial.\\nNoise can introduce spurious patterns and distortions, leading to erroneous predictions by the\\nmodel. To address this issue in future efforts, it may be necessary to refine the noise removal\\nprocess by experimenting with different thresholding techniques or adaptive thresholding methods.\\nAdditionally, incorporating data augmentation techniques during preprocessing, such as random\\nrotations, translations, or adding simulated noise, could help improve the robustness of the model\\nto noise artifacts. Furthermore, conducting thorough analysis and validation of the preprocessing\\nsteps, including the selection of optimal thresholds, is essential to ensure the quality and integrity\\nof the data before feeding it into the model. By addressing these challenges and refining the\\npreprocessing pipeline, future iterations of the research can strive for even greater accuracy and\\nreliability in classifying plant images and mitigating misclassification errors.\\n29', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 37}),\n",
       " Document(page_content='Chapter 7\\nConclusion and Future Work\\n7.1 Conclusion\\nIn our pursuit to optimize food disease picture classification, we embarked on a comprehensive inves-\\ntigation into a myriad of deep learning models, including DenseNet201, DenseNet121, ResNet50V2,\\nResNet101V2, VGG16, VGG19, MobileNetV2, and MobileNetV3. These models were selected\\nbased on their renowned feature extraction capabilities and their ability to strike a balance be-\\ntween computational efficiency and diagnostic accuracy. Our evaluation encompassed two standard\\ndatasets: the Potato Leaf Disease (PLD) dataset and the Fruit Infection Disease dataset, each pre-\\nsenting unique challenges and insights into disease classification in agricultural settings. Throughout\\nour experimentation, we explored a range of image resolutions, recognizing the potential benefits of\\nhigher resolutions within our computational constraints. For the PLD dataset, our model YYYY\\ndemonstrated great promise, achieving X1% and X2% accuracies, respectively, on 224 ×224×3 im-\\nages. Notably, by incorporating attention mechanisms, particularly the product rule strategy, our\\nmodel surpassed previous benchmarks, achieving an impressive X3% accuracy. Shifting our focus\\nto the Fruit Infection Disease dataset, the YYYY model achieved a commendable X% accuracy on\\n224×224×3 images, while the YYYY model reached X%. The integration of attention mechanisms\\nfurther elevated performance, achieving an impressive X% accuracy, marking significant progress\\nover the previous X% benchmark.\\n7.2 Future Work\\nOur research illuminates several promising directions for future development in food disease im-\\nage classification. As computational resources continue to evolve, there is a compelling need to\\nexplore even higher image resolutions, which hold the promise of significantly improving accuracy\\nby capturing finer details and nuances present in agricultural imagery. Furthermore, expanding\\nthe diversity and extent of datasets is imperative for bolstering the adaptability of deep learn-\\ning models to a broader spectrum of clinical scenarios, encompassing various crops, diseases, and\\nenvironmental conditions. Simultaneously, the adoption of explainable AI techniques emerges as\\ninstrumental in promoting transparency and trust among food disease professionals. By elucidating\\nthe decision-making processes of deep learning models, explainable AI techniques provide valuable\\n30', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 38}),\n",
       " Document(page_content='insights into the features and patterns driving classification outcomes, empowering stakeholders to\\ninterpret and validate model predictions effectively. Lastly, the advancements in transfer learn-\\ning techniques hold the potential to extend the applicability of our models to other food disease\\nimaging domains, facilitating knowledge transfer and accelerating progress in various branches of\\nagricultural research. By leveraging pre-trained models and domain-specific knowledge, transfer\\nlearning enables the adaptation of deep learning models to new datasets and tasks with reduced\\ndata and computational requirements. In conclusion, our research contributes towards these future\\nendeavors, aiming to refine and expand the capabilities of deep learning models in food disease\\nimage classification. By leveraging advanced techniques, harnessing computational resources, and\\nfostering collaboration across disciplines, we endeavor to develop robust and effective solutions for\\ncombating crop diseases and safeguarding global food security.\\n31', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 39}),\n",
       " Document(page_content='Bibliography\\n[1] J. Hu, L. Shen, and G. Sun. Squeeze-and-excitation networks. In Proceedings of the IEEE\\nconference on computer vision and pattern recognition , pages 7132–7141, 2018.\\n[2] B. N. Naik, R. Malmathanraj, and P. Palanisamy. Detection and classification of chilli leaf\\ndisease using a squeeze-and-excitation-based cnn model. Ecological Informatics , 69:101663,\\n2022.\\n[3] Y. J. Park, G. Tuxworth, and J. Zhou. Insect classification using squeeze-and-excitation and\\nattention modules-a benchmark study. In 2019 IEEE International Conference on Image Pro-\\ncessing (ICIP) , pages 3437–3441. IEEE, 2019.\\n[4] M. Patacchiola, J. Bronskill, A. Shysheya, K. Hofmann, S. Nowozin, and R. Turner. Con-\\ntextual squeeze-and-excitation for efficient few-shot image classification. Advances in Neural\\nInformation Processing Systems , 35:36680–36692, 2022.\\n[5] C. Qiu, S. Zhang, C. Wang, Z. Yu, H. Zheng, and B. Zheng. Improving transfer learning and\\nsqueeze-and-excitation networks for small-scale fine-grained fish image classification. IEEE\\nAccess , 6:78503–78512, 2018.\\n[6] A. G. Roy, N. Navab, and C. Wachinger. Concurrent spatial and channel ‘squeeze & exci-\\ntation’in fully convolutional networks. In Medical Image Computing and Computer Assisted\\nIntervention–MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20,\\n2018, Proceedings, Part I , pages 421–429. Springer, 2018.\\n[7] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recog-\\nnition, 2015.\\n[8] Y. Tang, J. Yang, Q. Xu, H. Wang, and H. Ding. Flower classification model based on improved\\nattention. In 2023 IEEE 3rd International Conference on Information Technology, Big Data\\nand Artificial Intelligence (ICIBA) , volume 3, pages 495–499. IEEE, 2023.\\n[9] L. Wang, J. Peng, and W. Sun. Spatial–spectral squeeze-and-excitation residual network for\\nhyperspectral image classification. Remote Sensing , 11(7):884, 2019.\\n[10] X. Zhong, O. Gong, W. Huang, L. Li, and H. Xia. Squeeze-and-excitation wide residual\\nnetworks in image classification. In 2019 IEEE International Conference on Image Processing\\n(ICIP) , pages 395–399. IEEE, 2019.\\n32', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 40}),\n",
       " Document(page_content='[11] D. Zoran, M. Chrzanowski, P.-S. Huang, S. Gowal, A. Mott, and P. Kohli. Towards robust\\nimage classification using sequential attention models. In Proceedings of the IEEE/CVF con-\\nference on computer vision and pattern recognition , pages 9483–9492, 2020.\\n33', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 41})]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader('MCA_Thesis (2).pdf')\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='An Empirical Study with Pre Trained and Attention Model\\non Food Disease Classification\\nA Project submitted in partial fulfillment of requirements\\nFor the award of the degree of\\nMaster of Computer Application\\nby\\nSohom Roy Choudhury\\nRegn. No.- 221040510049 Exam Roll No. - 12022010010038\\nRishav Bhattacharjee\\nRegn. No.- 221040510036 Exam Roll No. - 12022010010008\\nAyan Batabyal\\nRegn. No.- 221040510011 Exam Roll No. - 12022010010003\\nunder the supervision of\\nProf. Supratim Ghosh\\nAssistant Professor\\n&\\nProf. Dr. Priti Deb\\nAssistant Professor\\nDepartment of Computer Application\\nInstitute of Engineering & Management\\nKolkata, West Bengal, India\\n2022-2024', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 0}),\n",
       " Document(page_content='Declaration Certificate\\nThis is to certify that the work presented in the thesis entitled “An Empirical Study with\\nPre-Trained and Attention Model on Food Disease Classification” in partial fulfilment of\\nthe requirement for the award of degree of Master of Computer Application of Institute of\\nEngineering & Management is an authentic carried out under my supervision and guidance.\\nTo the best of my knowledge the content of this thesis dose not form a basis for the award of\\nany previous degree to anyone else.\\nProf. Supratim Ghosh ,\\nAssistant Professor,\\nDepartment of Computer Application,\\nInstitute of Engineering & Managemnet.\\n(Supervisor)\\nProf. Dr. Priti Deb ,\\nAssistant Professor,\\nDepartment of Computer Application,\\nInstitute of Engineering & Managemnet.\\n(Supervisor)\\nHead of the Department,\\nMaster of Computer Application and Sciences,\\nInstitute of Engineering & Management.\\nI', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 1}),\n",
       " Document(page_content='Certificate of Approval\\nThe for going thesis entitled “An Empirical Study with Pre-Trained and Attention\\nModel on Food Disease Classification” is hereby approved as a creditable study of research\\ntopic and has been presented in satisfactory manner to warrant its acceptance as prerequisite to\\nthe degree for which it has been submitted.\\nIt is understood by this approval, the undersigned do not necessarily endorse any conclusion or\\nopinion expressed there in, but approve the thesis for the purpose for which it is submitted.\\nExaminers:\\n(Signature of The Examiner) (Signature of The Supervisor)\\n(Signature of The Supervisor)\\nII', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 2}),\n",
       " Document(page_content='ACKNOWLEDGEMENT\\nWe would like to express our special thanks to our supervisor, Prof. Supratim Ghosh and Prof.\\nDr. Priti Deb who helped us a lot in this project, their valuable suggestions helped us to solve tough\\nchallenges and without their help this project could not have been completed in time. A special\\nthanks to them who gave us the golden oppurtunity to do this wonderful project on the topic “An\\nEmpirical Study with Pre Trained and Attention Model on Food Disease Classification”, which\\nhelped us to gain a significant knowledge in the aforesaid subjects. We would also like to express\\nour warm regards as a note of thanks to Prof. Dr. Pawan Kumar Singh of Jadavpur University(IT\\nDepartment) and Prof. Debam Saha of Calcutta Institute of Engineering and Management( CSE\\nDepartment) for their wonderful support for their help on this topic. Secondly, we would like to\\nthank our friends who helped us a lot in finalising this project within the given time frame.\\nSohom Roy Choudhury', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 3}),\n",
       " Document(page_content='thank our friends who helped us a lot in finalising this project within the given time frame.\\nSohom Roy Choudhury\\nRoll No. - 12022010010038\\nDepartment of Computer Application,\\nInstitute of Engineering & Management.\\nRishav Bhattacharjee\\nRoll No. - 12022010010008\\nDepartment of Computer Application,\\nInstitute of Engineering & Management.\\nAyan Batabyal\\nRoll No. - 12022010010003\\nDepartment of Computer Application,\\nInstitute of Engineering & Management.\\nIII', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 3})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings # Or OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "db_faiss = FAISS.from_documents(documents,OllamaEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='MobileNet 83 45 32\\nResNet101V2 82 35 32\\nDenseNet121 79 45 32\\nAs seen in the below Confusion matrix in Figure 6.7, MobileNet was able to identify Strawberry’s\\nLeaf Spot class correctly the best with 95% of the times the result being True Positive. MobileNet\\nperformed the worst against Strawberry’s Gray Mold class with 52% True Positivity. Beans’ Angular\\nLeaf spot class tricked MobileNet the most with 30% of the time it being classified as Beans’ Rust\\nclass. As seen in the below Confusion matrix in Figure 6.8, ResNet101V2 was able to identify\\nStrawberry’s Leaf Spot class correctly the best with 99% of the times the result being True Positive.\\nResNet101V2 performed the worst against Strawberry’s Gray Mold class with 50% True Positivity.\\nStrawberry’s Gray Mold class tricked ResNet101V2 the most with 32% of the time it being classified\\nas Strawberry’s Powdery Mildew Fruit class. As seen in the below Confusion matrix in Figure 6.9,', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 35}),\n",
       " Document(page_content='result, a small sample of images ended up being misclassified due to the presence of residual noise.\\nThe presence of noise in images can significantly impact the performance of machine learning\\nmodels, particularly in tasks like image classification, where accurate feature extraction is crucial.\\nNoise can introduce spurious patterns and distortions, leading to erroneous predictions by the\\nmodel. To address this issue in future efforts, it may be necessary to refine the noise removal\\nprocess by experimenting with different thresholding techniques or adaptive thresholding methods.\\nAdditionally, incorporating data augmentation techniques during preprocessing, such as random\\nrotations, translations, or adding simulated noise, could help improve the robustness of the model\\nto noise artifacts. Furthermore, conducting thorough analysis and validation of the preprocessing\\nsteps, including the selection of optimal thresholds, is essential to ensure the quality and integrity', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 37}),\n",
       " Document(page_content='main classes:\\n1.Early Blight: This class includes 1628 images of potato leaves exhibiting symptoms of\\nearly blight, a common fungal disease caused by the pathogen Alternaria solani. Early blight\\ntypically manifests as dark lesions with concentric rings on the leaves, leading to reduced\\nplant vigor and yield loss if left untreated.\\n2.Late Blight: The Late Blight class consists of 1414 images depicting potato leaves affected by\\nlate blight, a devastating disease caused by the oomycete pathogen Phytophthora infestans.\\nLate blight is characterized by water-soaked lesions that rapidly spread and can decimate\\nentire potato crops if not controlled effectively.\\n3.Healthy: This class comprises 1020 images of healthy potato leaves, devoid of any disease\\nsymptoms or abnormalities. Healthy leaves serve as a reference for comparison, enabling\\nresearchers to distinguish between diseased and non-diseased samples accurately.', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 25}),\n",
       " Document(page_content='mentation serves as a pivotal motivation for the present study. By\\nincorporating attention layers, the thesis demonstrates a notable im-\\nprovement in accuracy levels, underscoring the potential of attention\\nmechanisms in deep learning-based disease classification tasks. Such\\nfindings not only advance the understanding of deep learning applica-\\ntions in disease diagnosis but also highlight the importance of attention\\nmechanisms in refining model performance.\\nKeyword: Deep Learning, Food Disease Classification, Squeeze and\\nExcitation, DenseNet201, DenseNet121, ResNet50V2, ResNet101V2,\\nVGG16, VGG19, MobileNetV2, MobileNet, Potato Leaf Disease (PLD)\\nand Food Infection Disease (FID).', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 8})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"What is the summary of this paper\"\n",
    "res = db_faiss.similarity_search(query)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ollama()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama2\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design ChatPrompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Answer the questions based only on the provided context.\n",
    "                                          Think step by step before providing a detailed answer.\n",
    "                                          I will tip you $1000 if the answer finds the answer useful.\n",
    "                                          <context>\n",
    "                                          {context}\n",
    "                                          </context>\n",
    "                                          Question: {input}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Introduction\n",
    "#### Create Stuff Document Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000221A22C4690>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db_faiss.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'The primary objective is to assess their efficacy in accurately classifying a broad',\n",
       " 'context': [Document(page_content='result, a small sample of images ended up being misclassified due to the presence of residual noise.\\nThe presence of noise in images can significantly impact the performance of machine learning\\nmodels, particularly in tasks like image classification, where accurate feature extraction is crucial.\\nNoise can introduce spurious patterns and distortions, leading to erroneous predictions by the\\nmodel. To address this issue in future efforts, it may be necessary to refine the noise removal\\nprocess by experimenting with different thresholding techniques or adaptive thresholding methods.\\nAdditionally, incorporating data augmentation techniques during preprocessing, such as random\\nrotations, translations, or adding simulated noise, could help improve the robustness of the model\\nto noise artifacts. Furthermore, conducting thorough analysis and validation of the preprocessing\\nsteps, including the selection of optimal thresholds, is essential to ensure the quality and integrity', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 37}),\n",
       "  Document(page_content='the development of deeper and more expressive models, ResNet architectures have unlocked new\\nfrontiers in visual recognition, pushing the boundaries of what is achievable in terms of accuracy\\nand efficiency. Furthermore, the success of ResNet models has inspired further innovations in neural\\nnetwork architecture design, with researchers continually exploring new techniques for improving\\nthe performance and efficiency of deep learning models. From inception, ResNet has served as a\\ncatalyst for innovation, sparking a wave of research aimed at addressing the challenges inherent\\nin training deep neural networks. In conclusion, the introduction of skip connections in ResNet\\narchitectures like ResNet-50v2 and ResNet-101v2 represented a paradigm shift in the field of deep\\nlearning. By mitigating issues such as vanishing gradients, these architectures enabled the train-\\ning of exceptionally deep neural networks, pushing the boundaries of what is achievable in terms', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 18}),\n",
       "  Document(page_content='summing the True Positives (TP), False Negatives (FN), and False Positives (FP). To\\nobtain the micro F1 score, the TP, FP, and FN values across all classes are aggregated.\\n6.3 Confusion Matrix\\nThe assessment of classification models’ performance on a specific test dataset involves the use of\\na matrix known as the confusion matrix. This matrix can be computed only after obtaining the\\nactual values of the test data. While the structure of the matrix is straightforward to grasp, certain\\nterminologies associated with it might be perplexing. Occasionally labeled as an error matrix, it\\nillustrates the shortcomings in the model’s performance in matrix form.\\n6.4 Experimental Result\\nThis section scrutinizes the results produced by the eight deep learning models. The findings of\\nthe fundamental learners are visually depicted. Certain models demonstrate superior accuracy in\\nidentifying specific vehicles compared to others. Furthermore, a classification report detailing the', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 32}),\n",
       "  Document(page_content='Bibliography\\n[1] J. Hu, L. Shen, and G. Sun. Squeeze-and-excitation networks. In Proceedings of the IEEE\\nconference on computer vision and pattern recognition , pages 7132–7141, 2018.\\n[2] B. N. Naik, R. Malmathanraj, and P. Palanisamy. Detection and classification of chilli leaf\\ndisease using a squeeze-and-excitation-based cnn model. Ecological Informatics , 69:101663,\\n2022.\\n[3] Y. J. Park, G. Tuxworth, and J. Zhou. Insect classification using squeeze-and-excitation and\\nattention modules-a benchmark study. In 2019 IEEE International Conference on Image Pro-\\ncessing (ICIP) , pages 3437–3441. IEEE, 2019.\\n[4] M. Patacchiola, J. Bronskill, A. Shysheya, K. Hofmann, S. Nowozin, and R. Turner. Con-\\ntextual squeeze-and-excitation for efficient few-shot image classification. Advances in Neural\\nInformation Processing Systems , 35:36680–36692, 2022.\\n[5] C. Qiu, S. Zhang, C. Wang, Z. Yu, H. Zheng, and B. Zheng. Improving transfer learning and', metadata={'source': 'MCA_Thesis (2).pdf', 'page': 40})],\n",
       " 'answer': 'The primary objective is to assess the efficiency of deep learning models in accurately classifying a broad range of images, including those with residual noise. To address this issue, several techniques can be employed:\\n\\n1. Noise reduction techniques: Using thresholding techniques or adaptive thresholding methods can help remove residual noise from images before classification.\\n2. Data augmentation: Incorporating data augmentation techniques during preprocessing can simulate different scenarios and help improve the robustness of the model to noise artifacts.\\n3. Model selection: Choosing an appropriate deep learning architecture, such as ResNet, can help mitigate issues related to vanishing gradients and improve the trainability of exceptionally deep neural networks.\\n4. Performance evaluation: Assessing the performance of the developed models using a confusion matrix can provide insights into their accuracy in identifying specific vehicles and other objects.\\n5. Experimental results: Visualizing the findings of the eight deep learning models can help identify which models demonstrate superior accuracy in identifying specific vehicles compared to others.\\n\\nTo address the issue of residual noise in images, several techniques can be employed:\\n\\n1. Noise reduction techniques: Using thresholding techniques or adaptive thresholding methods can help remove residual noise from images before classification.\\n2. Data augmentation: Incorporating data augmentation techniques during preprocessing can simulate different scenarios and help improve the robustness of the model to noise artifacts.\\n3. Model selection: Choosing an appropriate deep learning architecture, such as ResNet, can help mitigate issues related to vanishing gradients and improve the trainability of exceptionally deep neural networks.\\n4. Performance evaluation: Assessing the performance of the developed models using a confusion matrix can provide insights into their accuracy in identifying specific vehicles and other objects.\\n5. Experimental results: Visualizing the findings of the eight deep learning models can help identify which models demonstrate superior accuracy in identifying specific vehicles compared to others.\\n\\nIn conclusion, addressing the issue of residual noise in images is crucial for improving the efficiency of deep learning models in image classification tasks. By employing various techniques, such as noise reduction methods, data augmentation, model selection, performance evaluation, and experimental results, it is possible to develop more accurate and robust models for image classification.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\":\"The primary objective is to assess their efficacy in accurately classifying a broad\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
